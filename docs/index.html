<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="AI Agent Playing PokÃ©mon Emerald with VLM-based Code Generation and Expert-Guided Reinforcement Learning">
    <meta name="author" content="Junik Bae">

    <!-- Open Graph meta tags -->
    <meta property="og:title" content="PokÃ©Agent Challenge - VLM-based RL Speedrunning">
    <meta property="og:description" content="1st Place NeurIPS 2025 PokÃ©Agent Challenge - Expert-Guided RL">
    <meta property="og:image" content="static/images/emerald.png">
    <meta property="og:type" content="website">

    <title>PokÃ©Agent Challenge - VLM-based Code Generation & Expert-Guided RL</title>

    <link rel="stylesheet" href="static/css/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-background">
            <img src="static/images/emerald.png" alt="Pokemon Emerald" class="hero-bg-img">
            <div class="hero-overlay"></div>
        </div>
        <div class="hero-content">
            <h1 class="hero-title">PokÃ©Agent Challenge</h1>
            <p class="hero-subtitle">AI Agent Playing PokÃ©mon Emerald with VLM-based Code Generation<br>and Expert-Guided Reinforcement Learning</p>
            <div class="hero-buttons">
                <a href="https://github.com/heatz123/pokeagent-solution" class="btn btn-primary" target="_blank">
                    <i class="fab fa-github"></i> GitHub Repository
                </a>
                <a href="https://www.youtube.com/@Heatzheatzheatz" class="btn btn-secondary" target="_blank">
                    <i class="fab fa-youtube"></i> YouTube Demos
                </a>
                <a href="https://pokeagent.github.io/" class="btn btn-tertiary" target="_blank">
                    <i class="fas fa-trophy"></i> NeurIPS 2025 Challenge
                </a>
            </div>
            <div class="hero-badge">
                <span class="badge-gold"><i class="fas fa-medal"></i> 1st Place</span>
                <span class="badge-info">NeurIPS 2025 PokÃ©Agent Challenge</span>
            </div>
            <p class="hero-author">Junik Bae, Seoul National University</p>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section section-abstract">
        <div class="container">
            <h2 class="section-title">Abstract</h2>
            <div class="abstract-content">
                <p>
                    We present a <strong>knowledge-based, expert-guided reinforcement learning approach</strong> for playing PokÃ©mon Emerald.
                    Our method externalizes the game knowledge of a Vision-Language Model (VLM) into <strong>Python code expert policies</strong>,
                    which serve as teachers for training pixel-based neural network agents.
                </p>
                <p>
                    The trained agent ranked <strong class="highlight">1st place</strong> on the NeurIPS 2025 PokÃ©Agent Challenge Speedrun track,
                    achieving the first gym (Roxanne) in <strong class="highlight">40 minutes and 13 seconds</strong> â€” without complex reward
                    engineering or large-scale human demonstrations.
                </p>
            </div>
        </div>
    </section>

    <!-- Demo Videos Section -->
    <section class="section section-videos">
        <div class="container">
            <h2 class="section-title">Agent Demonstrations</h2>
            <p class="section-description">Watch our trained agent speedrun through PokÃ©mon Emerald</p>

            <div class="videos-grid">
                <div class="video-card">
                    <div class="video-container">
                        <video controls preload="metadata">
                            <source src="static/videos/final1_2x.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <div class="video-caption">
                        <h3>ROUTE101_TO_OLDALE</h3>
                        <p>RL agent discovers more efficient routing and autonomously selects RUN to skip unnecessary wild battles</p>
                        <p class="video-meta"><i class="fas fa-clock"></i> 2x speed</p>
                    </div>
                </div>

                <div class="video-card">
                    <div class="video-container">
                        <video controls preload="metadata">
                            <source src="static/videos/final2_2x.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <div class="video-caption">
                        <h3>EXIT_BIRCH_LAB</h3>
                        <p>Agent learns to skip the PokÃ©mon nickname input UI through emergent behavior discovery</p>
                        <p class="video-meta"><i class="fas fa-clock"></i> 2x speed</p>
                    </div>
                </div>
            </div>

            <div class="youtube-link">
                <a href="https://www.youtube.com/@Heatzheatzheatz" target="_blank" class="btn btn-youtube">
                    <i class="fab fa-youtube"></i> Watch More on YouTube
                </a>
            </div>
        </div>
    </section>

    <!-- Key Features Section -->
    <section class="section section-features">
        <div class="container">
            <h2 class="section-title">Key Features</h2>

            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-code"></i>
                    </div>
                    <h3>VLM Code Generation</h3>
                    <p>Generate Python expert policies using Vision-Language Models (GPT-4o, Gemini 2.5)</p>
                </div>

                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-graduation-cap"></i>
                    </div>
                    <h3>Expert-Guided RL</h3>
                    <p>DAgger-style imitation learning combined with Double DQN reinforcement learning</p>
                </div>

                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-brain"></i>
                    </div>
                    <h3>Pure Pixel Neural Network</h3>
                    <p>Final agent operates purely on raw pixels without VLM at inference time</p>
                </div>

                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-list-check"></i>
                    </div>
                    <h3>Milestone-Based Curriculum</h3>
                    <p>Decompose long-horizon gameplay into manageable subgoals with clear success criteria</p>
                </div>

                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-lightbulb"></i>
                    </div>
                    <h3>Emergent Behaviors</h3>
                    <p>Agent discovers strategies beyond expert code: battle skipping, efficient routing</p>
                </div>

                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-chart-line"></i>
                    </div>
                    <h3>No Reward Engineering</h3>
                    <p>Simple sparse rewards with VLM guidance - no complex reward shaping required</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Methodology Section -->
    <section class="section section-methodology">
        <div class="container">
            <h2 class="section-title">Methodology</h2>

            <div class="methodology-pipeline">
                <h3>Pipeline Overview</h3>
                <div class="pipeline-steps">
                    <div class="pipeline-step">
                        <div class="step-number">1</div>
                        <h4>Milestone Decomposition</h4>
                        <p>Break down long-horizon game into subgoals with clear start states and success criteria</p>
                    </div>

                    <div class="pipeline-arrow">â†’</div>

                    <div class="pipeline-step">
                        <div class="step-number">2</div>
                        <h4>VLM Code Expert Generation</h4>
                        <p>Vision-Language Model analyzes game state and generates Python code to solve each milestone</p>
                    </div>

                    <div class="pipeline-arrow">â†’</div>

                    <div class="pipeline-step">
                        <div class="step-number">3</div>
                        <h4>Expert-Guided Policy Learning</h4>
                        <p><strong>DAgger:</strong> Collect expert demonstrations on-policy<br>
                           <strong>DDQN:</strong> Reinforce and improve beyond expert baseline</p>
                    </div>

                    <div class="pipeline-arrow">â†’</div>

                    <div class="pipeline-step">
                        <div class="step-number">4</div>
                        <h4>Pure CNN Policy</h4>
                        <p>Final agent: raw pixels â†’ actions (no VLM at inference)</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section class="section section-results">
        <div class="container">
            <h2 class="section-title">Results</h2>

            <h3>NeurIPS 2025 PokÃ©Agent Challenge Leaderboard</h3>
            <div class="leaderboard-table">
                <table>
                    <thead>
                        <tr>
                            <th>Rank</th>
                            <th>Team</th>
                            <th>Method</th>
                            <th>Time to First Gym</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="rank-1">
                            <td><span class="medal gold">ðŸ¥‡ 1st</span></td>
                            <td><strong>Ours</strong></td>
                            <td>VLM Code Expert + Expert-Guided RL</td>
                            <td><strong>40:13</strong></td>
                        </tr>
                        <tr>
                            <td><span class="medal silver">ðŸ¥ˆ 2nd</span></td>
                            <td>Hamburg PokeRunners</td>
                            <td>PPO with recurrent network (reward shaping)</td>
                            <td>01:14:43</td>
                        </tr>
                        <tr>
                            <td><span class="medal bronze">ðŸ¥‰ 3rd</span></td>
                            <td>anthonys</td>
                            <td>Tool-Calling VLM Policy</td>
                            <td>01:29:17</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Quantitative Analysis</h3>
            <div class="results-grid">
                <div class="result-card">
                    <h4>LITTLEROOT_TO_ROUTE101 Milestone</h4>
                    <table class="results-table">
                        <tr>
                            <td>Naive RL</td>
                            <td class="result-fail">timeout (failed)</td>
                        </tr>
                        <tr>
                            <td>Expert-only</td>
                            <td>90.15 steps (Â±33.7)</td>
                        </tr>
                        <tr class="result-best">
                            <td><strong>Expert-guided RL</strong></td>
                            <td><strong>55.75 steps (Â±12.9) âœ¨</strong></td>
                        </tr>
                    </table>
                </div>

                <div class="result-card">
                    <h4>EXIT_BIRCH_LAB Milestone</h4>
                    <table class="results-table">
                        <tr>
                            <td>Naive RL</td>
                            <td class="result-fail">timeout (failed)</td>
                        </tr>
                        <tr>
                            <td>Expert-only</td>
                            <td>64.40 steps (Â±1.0)</td>
                        </tr>
                        <tr class="result-best">
                            <td><strong>Expert-guided RL</strong></td>
                            <td><strong>56.35 steps (Â±1.1) âœ¨</strong></td>
                        </tr>
                    </table>
                </div>
            </div>

            <h3>Qualitative Discoveries</h3>
            <div class="discoveries">
                <p>The learned RL policy autonomously discovered strategies <strong>not explicitly encoded in the expert code</strong>:</p>
                <ul class="discoveries-list">
                    <li><i class="fas fa-check-circle"></i> <strong>Efficient route selection</strong> â€” avoiding unnecessary detours and optimizing pathfinding</li>
                    <li><i class="fas fa-check-circle"></i> <strong>Skipping wild battles</strong> â€” using RUN command to quickly exit encounters</li>
                    <li><i class="fas fa-check-circle"></i> <strong>Fast-forwarding UI interactions</strong> â€” nickname input skip via START+A combo</li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Contributions Section -->
    <section class="section section-contributions">
        <div class="container">
            <h2 class="section-title">Key Contributions</h2>

            <div class="contributions-grid">
                <div class="contribution-card">
                    <div class="contribution-number">1</div>
                    <h3>Knowledge-Based Expert-Guided RL Pipeline</h3>
                    <p>Propose VLM code expert generation for long-horizon pixel games, combining milestone structure, code experts, and RL training</p>
                </div>

                <div class="contribution-card">
                    <div class="contribution-number">2</div>
                    <h3>Practical Alternative to Reward Engineering</h3>
                    <p>No complex reward shaping required, no large-scale human demonstration collection â€” simple sparse rewards + VLM guidance</p>
                </div>

                <div class="contribution-card">
                    <div class="contribution-number">3</div>
                    <h3>Competitive Performance</h3>
                    <p>1st place on NeurIPS 2025 PokÃ©Agent Challenge, faster than human demonstration baselines, with emergent behaviors beyond expert code</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-section">
                    <h3>PokÃ©Agent Challenge</h3>
                    <p>AI Agent for PokÃ©mon Emerald Speedrunning</p>
                    <p class="copyright">Â© 2025 Junik Bae, Seoul National University</p>
                </div>

                <div class="footer-section">
                    <h3>Links</h3>
                    <ul class="footer-links">
                        <li><a href="https://github.com/heatz123/pokeagent-solution" target="_blank"><i class="fab fa-github"></i> GitHub Repository</a></li>
                        <li><a href="https://www.youtube.com/@Heatzheatzheatz" target="_blank"><i class="fab fa-youtube"></i> YouTube Channel</a></li>
                        <li><a href="https://pokeagent.github.io/" target="_blank"><i class="fas fa-trophy"></i> NeurIPS 2025 Challenge</a></li>
                    </ul>
                </div>

                <div class="footer-section">
                    <h3>License</h3>
                    <p><a href="https://github.com/heatz123/pokeagent-solution/blob/main/LICENSE" target="_blank">MIT License</a></p>
                    <p>Feel free to use and modify with attribution</p>
                </div>
            </div>
        </div>
    </footer>

    <script src="static/js/main.js"></script>
</body>
</html>
