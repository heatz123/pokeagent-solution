#!/usr/bin/env python3
"""
Code-generating agent that uses OpenAI Vision API to generate Python code
which is then executed to determine game actions.
"""

import openai
import os
import time
import io
import json
import base64
import signal
import random
from utils.llm_logger import get_llm_logger
from utils.state_formatter import convert_state_to_dict, filter_state_for_llm
from utils.milestone_manager import MilestoneManager
from utils.prompt_builder import CodeAgentPromptBuilder, CodePromptConfig
from utils.stuck_detector import StuckDetector
from utils.knowledge_base import KnowledgeBase
from utils.subtask_manager import SubtaskManager
from utils.vlm_state import State, get_global_schema_registry, add_to_state_schema
from utils.vlm_caller import VLMCaller
from utils.context_summarizer import ContextSummarizer


class CodeAgent:
    """Agent that generates and executes Python code to determine actions"""

    # Known section headers for response parsing
    # These are the possible headers that can appear after ANALYSIS
    SECTION_HEADERS = [
        'OBJECTIVES:',
        'KNOWLEDGE_UPDATE:',
        'PLAN:',
        'REASONING:',
        'TASK_DECOMPOSITION:',
        'CODE:'
    ]

    def __init__(self, model="gpt-5"):
        """Initialize the CodeAgent with OpenAI, Claude, or Gemini"""

        # Initialize client based on model
        if model == "gpt-5":
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY environment variable not set")
            self.client = openai.OpenAI(api_key=api_key)
            self.provider = "openai"

        elif model == "claude-sonnet-4-5-20250929":
            import anthropic
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY environment variable not set")
            self.client = anthropic.Anthropic(api_key=api_key)
            self.provider = "claude"

        elif "gemini" in model.lower():
            import google.generativeai as genai
            api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
            if not api_key:
                raise ValueError("GEMINI_API_KEY or GOOGLE_API_KEY environment variable not set")
            genai.configure(api_key=api_key)
            self.client = genai.GenerativeModel(model)
            self.genai = genai
            self.provider = "gemini"

        else:
            raise ValueError(f"Unsupported model: {model}. Use 'gpt-5', 'claude-sonnet-4-5-20250929', or 'gemini-2.5-flash'")

        self.model = model
        self.llm_logger = get_llm_logger()
        self.step_count = 0
        self.last_code_generation_step = 0

        # Milestone manager (like SimpleAgent's objectives)
        self.milestone_manager = MilestoneManager()

        # Subtask manager for dynamic task decomposition
        self.subtask_manager = SubtaskManager(self.milestone_manager)

        # Subtask feature flag (enable/disable subtask-based execution)
        self.use_subtasks = os.getenv("USE_SUBTASKS", "false").lower() == "true"

        # Knowledge base feature flag (enable/disable knowledge persistence)
        self.use_knowledge_base = os.getenv("USE_KNOWLEDGE_BASE", "true").lower() == "true"

        # Custom milestone completion tracking (client-side only)
        self.custom_milestone_completions = {}

        # Stuck detector (threshold=3)
        self.stuck_detector = StuckDetector(threshold=3)

        # Code caching
        self.last_generated_code = None
        self.code_generation_count = 0

        # Execution error tracking
        self.last_execution_error = None

        # Prompt builder for structured prompt generation
        self.prompt_builder = CodeAgentPromptBuilder(
            config=CodePromptConfig(
                include_visual_note=True,
                include_milestones=True,
                include_example_code=True,
                include_knowledge_update=self.use_knowledge_base,
                include_execution_logs=True
            )
        )

        # Knowledge base for persistent learning across runs
        self.knowledge_base = KnowledgeBase() if self.use_knowledge_base else None

        # VLM caller for visual observations (Gemini or Ollama)
        vlm_model = os.getenv("VLM_MODEL", "gemini-2.5-flash-lite")
        self.vlm_caller = VLMCaller(model=vlm_model)

        # Context summarization settings
        self.analysis_threshold = int(os.getenv("ANALYSIS_THRESHOLD", "20"))

        # Context summarizer for periodic analysis compression
        self.summarizer = ContextSummarizer(
            llm_client=self.client,
            provider=self.provider,
            model=self.model
        )

        # Store previous ANALYSIS sections
        # When count reaches threshold (default 20), all are summarized into 1 entry
        self.previous_analyses = []

        # Track actions generated by current code (for debugging stuck patterns)
        self.actions_since_last_generation = []

        # Track last action for custom milestone checking
        self._last_action = None

        # Execution logs from code runs (for debugging and context)
        self.execution_logs = []  # List of (step_count, message) tuples
        self.max_logs = 100  # Maximum number of logs to keep

        # Screenshot history for visual context (stored with each step)
        self.screenshot_history = []  # List of (step_count, frame) tuples
        self.max_screenshot_history = 100  # Keep last 100 to prevent memory issues

        # Register custom milestones
        self._register_custom_milestones()

    def step(self, game_state):
        """
        Unified step function for both subtask and non-subtask modes

        Args:
            game_state: Dict with keys:
                - 'frame': PIL Image
                - 'player': player info dict
                - 'game': game info dict
                - 'map': map info dict
                - 'visual': visual info dict

        Returns:
            {'action': 'up'} or {'action': ['up', 'a']}
        """
        self.step_count += 1

        try:
            # 1. Get milestone info (common)
            augmented_milestones = self._get_augmented_milestones(game_state)
            next_milestone_info = self.milestone_manager.get_next_milestone_info(augmented_milestones)

            if not next_milestone_info:
                print("üéâ All milestones completed!")
                return {'action': 'b'}  # Wait

            # 2. Subtask-specific: Load subtask state and determine situation
            current_subtask = None
            situation = None

            if self.use_subtasks:
                # Load saved subtask state for this milestone
                self.subtask_manager.load_state(next_milestone_info['id'])
                current_subtask = self.subtask_manager.get_current_subtask()
                situation = self.determine_situation(current_subtask, game_state)

                # Check 30-step timeout and override situation if needed
                steps_since_generation = self.step_count - self.last_code_generation_step
                if steps_since_generation >= 30 and situation == "NORMAL":
                    situation = "STUCK"
                    print(f"‚è∞ 30 steps passed ({steps_since_generation}) - treating as STUCK")

                print(f"\n{'='*60}")
                print(f"Milestone: {next_milestone_info['description']}")
                print(f"Subtask: {current_subtask['description'] if current_subtask else 'None'}")
                print(f"Situation: {situation}")
                print(f"{'='*60}")

            # 3. Check stuck/need regeneration (common, but different logic)
            need_new_code = False

            if self.use_subtasks:
                # Subtask mode: Regenerate for non-NORMAL or no code
                need_new_code = (
                    situation != "NORMAL" or
                    not current_subtask or
                    not current_subtask.get('code')
                )
            else:
                # Non-subtask mode: Check stuck and other conditions
                is_stuck = self.stuck_detector.check_stuck(game_state)
                steps_since_generation = self.step_count - self.last_code_generation_step
                need_new_code = (
                    self.last_execution_error or
                    is_stuck or
                    self.last_generated_code is None or
                    steps_since_generation >= 30
                )

            # 4. Code selection/generation
            if need_new_code:
                # Generate new code
                if self.use_subtasks:
                    # Clear completed subtask before generating new code
                    if situation == "SUCCESS_ACHIEVED" and current_subtask:
                        print(f"‚úÖ Subtask completed: {current_subtask['description']}")
                        self.subtask_manager.clear_current_subtask()
                        current_subtask = None

                    print(f"ü§ñ Generating new code for {situation} situation...")
                    _, parsed = self._generate_new_code(
                        game_state,
                        is_stuck=False,  # Not used in subtask mode
                        current_subtask=current_subtask,
                        situation=situation
                    )

                    # Handle task decomposition
                    if parsed['task_decision'] in ['CREATE_OR_MODIFY', 'DECOMPOSE']:
                        if parsed.get('new_subtask'):
                            new_sub = parsed['new_subtask']
                            # Check if modifying conditions (same description) or creating new subtask
                            if current_subtask and new_sub['description'].strip() == current_subtask['description'].strip():
                                # Modify existing subtask conditions
                                current_subtask['precondition'] = new_sub['precondition']
                                current_subtask['success_condition'] = new_sub['success_condition']
                                print(f"üîß Updated conditions for current subtask: {current_subtask['description']}")
                            else:
                                # Create new subtask
                                current_subtask = self.create_next_subtask(
                                    next_milestone_info,
                                    parsed['new_subtask'],
                                    game_state
                                )
                        else:
                            print("‚ö†Ô∏è No subtask data despite CREATE_OR_MODIFY/DECOMPOSE decision")

                    # Save code to current subtask
                    if current_subtask and parsed.get('code'):
                        current_subtask['code'] = parsed['code']

                    # Save subtask state
                    if current_subtask:
                        self.subtask_manager.save_state(next_milestone_info['id'])

                    code = parsed.get('code', '')

                    # Update generation tracking (for 30-step timeout)
                    self.last_code_generation_step = self.step_count
                    self.code_generation_count += 1
                else:
                    # Non-subtask mode
                    code = self._generate_new_code(game_state, is_stuck)
                    self.last_generated_code = code
                    self.code_generation_count += 1
                    self.last_code_generation_step = self.step_count
            else:
                # Reuse existing code
                if self.use_subtasks:
                    code = current_subtask['code']
                    print("‚ÑπÔ∏è Reusing existing subtask code...")
                else:
                    code = self.last_generated_code
                    print(f"üîÑ Reusing previous code (generation #{self.code_generation_count})")

            # 5. Execute code (common)
            action = self._execute_code(code, game_state)

            if self.use_subtasks:
                print(f"‚úÖ Action: {action}")

            # 6. Post-execution tasks (common)
            self._check_custom_milestones(game_state, action)
            self.stuck_detector.record_action(action)

            # Record action with position before execution
            player = game_state.get('player', {})
            position = player.get('position', {})
            pos_tuple = (position.get('x'), position.get('y'))
            self.actions_since_last_generation.append((pos_tuple, action))

            self._last_action = action

            # Non-subtask specific: reset stuck detector
            if not self.use_subtasks and need_new_code:
                is_stuck = self.stuck_detector.check_stuck(game_state)
                if is_stuck:
                    self.stuck_detector.reset()

            # Save screenshot for visual history
            frame = game_state.get('frame')
            if frame:
                self.screenshot_history.append((self.step_count, frame))
                # Keep only recent screenshots to prevent memory issues
                if len(self.screenshot_history) > self.max_screenshot_history:
                    self.screenshot_history = self.screenshot_history[-self.max_screenshot_history:]

            return {'action': action}

        except Exception as e:
            print(f"‚ùå CodeAgent error: {e}")
            import traceback
            traceback.print_exc()
            return {'action': 'b'}  # Default action on error

    def _generate_new_code(
        self,
        game_state,
        is_stuck: bool,
        current_subtask=None,  # NEW: for subtask mode
        situation=None          # NEW: for subtask mode
    ):
        """
        Generate new code (unified for both modes)

        Args:
            game_state: Game state
            is_stuck: Whether stuck (non-subtask mode)
            current_subtask: Current subtask (subtask mode only)
            situation: Situation (subtask mode only)

        Returns:
            str: Generated code (non-subtask mode)
            tuple: (response_text, parsed_dict) (subtask mode)
        """
        # Common preparations
        previous_actions = self.actions_since_last_generation.copy()
        self.actions_since_last_generation = []

        # Convert and filter state for LLM
        formatted = convert_state_to_dict(game_state)
        filtered = filter_state_for_llm(formatted)
        state_text = json.dumps(filtered, indent=2, default=str)

        # Get recent screenshots (returns list of (step, frame) tuples)
        # Fixed to last 10 screenshots for consistency across all providers
        frames_to_send = self._get_recent_screenshots(max_count=10)

        # Milestone info (common)
        augmented_milestones = self._get_augmented_milestones(game_state)
        next_milestone_info = self.milestone_manager.get_next_milestone_info(augmented_milestones)
        current_milestone = next_milestone_info['id'] if next_milestone_info else 'unknown'

        # Build prompt (branching!)
        if self.use_subtasks:
            # For subtask mode, get previous code from current_subtask if available
            previous_code_value = ""
            if situation == "STUCK":
                if current_subtask and current_subtask.get('code'):
                    previous_code_value = current_subtask['code']
                elif self.last_generated_code:
                    previous_code_value = self.last_generated_code

            # Subtask-specific prompt (now with reused sections!)
            prompt = self.prompt_builder.build_subtask_prompt(
                main_milestone=next_milestone_info,
                current_subtask=current_subtask,
                situation=situation,
                state=game_state,
                milestone_manager=self.milestone_manager,
                subtask_manager=self.subtask_manager,
                # Ï∂îÍ∞Ä ÌååÎùºÎØ∏ÌÑ∞Îì§ (Ïû¨ÏÇ¨Ïö© ÏÑπÏÖòÏö©)
                execution_error=self.last_execution_error,
                previous_code=previous_code_value,
                knowledge_base=self.knowledge_base if self.use_knowledge_base else None,
                previous_analyses=self.previous_analyses,
                execution_logs=self.execution_logs,
                include_state_schema=False,  # State structure Î∂àÌïÑÏöî
                num_screenshots=len(frames_to_send) if frames_to_send else 1
            )
        else:
            # Non-subtask prompt
            stuck_warning = self.stuck_detector.get_stuck_warning()
            previous_code_raw = self.last_generated_code if is_stuck else ""

            prompt = self.prompt_builder.build_prompt(
                formatted_state=state_text,
                next_milestone_info=next_milestone_info,
                current_subtask=self.subtask_manager.get_current_subtask() if self.use_subtasks else None,
                stuck_warning=stuck_warning,
                previous_code=previous_code_raw,
                execution_error=self.last_execution_error,
                knowledge_base=self.knowledge_base if self.use_knowledge_base else None,
                previous_actions=previous_actions,
                previous_analyses=self.previous_analyses,
                execution_logs=self.execution_logs,
                num_screenshots=len(frames_to_send) if frames_to_send else 1
            )

        # Unified LLM call with labeled screenshots
        start = time.time()
        response = self._call_llm(prompt, frames_to_send)
        duration = time.time() - start

        # Clear execution logs (new code generation = fresh start)
        self.execution_logs = []

        # Log interaction (common)
        self.llm_logger.log_interaction(
            interaction_type="code_generation",
            prompt=prompt,
            response=response,
            duration=duration,
            model_info={"model": self.model, "tokens": {"prompt": 0, "completion": 0}}
        )

        # Knowledge base update (common for both modes)
        if self.use_knowledge_base:
            self._parse_and_update_knowledge(response, current_milestone)

        # Extract and store ANALYSIS section (common for both modes)
        analysis_text = self._extract_analysis(response)
        if analysis_text:
            self.previous_analyses.append((self.step_count, analysis_text))
            print(f"üìä ANALYSIS extracted (count: {len(self.previous_analyses)}/{self.analysis_threshold})")

            # Check if we should summarize analyses
            if self._should_summarize_analyses():
                print(f"üîî Triggering summarization at {len(self.previous_analyses)} analyses")
                self._summarize_and_reset_analyses()
        else:
            print(f"‚ö†Ô∏è No ANALYSIS section found in LLM response (step {self.step_count})")

        # Clear error after successful code generation (common for both modes)
        self.last_execution_error = None

        # Extract code and return (branching!)
        if self.use_subtasks:
            # Subtask mode: Parse full response
            parsed = self.parse_unified_response(response)
            code = parsed.get('code', '')
            return response, parsed  # Return both for subtask processing
        else:
            # Non-subtask mode: Extract code
            code = self._extract_code(response)

            # Milestone info output
            if next_milestone_info:
                print(f"üìç Next Milestone: {next_milestone_info['id']}")
            else:
                print(f"üèÜ All Milestones Complete!")

            return code

    def _get_screenshot_base64(self, game_state):
        """Get base64 screenshot from game state"""
        frame = game_state.get('frame')
        if frame:
            buffer = io.BytesIO()
            frame.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode()
        return ""

    def _get_screenshot_base64_from_frame(self, frame):
        """Get base64 screenshot from PIL Image frame"""
        if frame:
            buffer = io.BytesIO()
            frame.save(buffer, format='PNG')
            return base64.b64encode(buffer.getvalue()).decode()
        return ""

    def _get_recent_screenshots(self, max_count=10):
        """
        Get recent screenshots since last code generation

        Args:
            max_count: Maximum number of screenshots to return (default: 10)

        Returns:
            List of (step_count, PIL.Image) tuples (ÏµúÎåÄ max_countÍ∞ú, ÏãúÍ∞ÑÏàú)
        """
        if not self.screenshot_history:
            return []

        # Filter screenshots since last code generation
        recent_screenshots = [
            (step, frame) for step, frame in self.screenshot_history
            if step >= self.last_code_generation_step
        ]

        # Take last max_count screenshots
        recent_screenshots = recent_screenshots[-max_count:]

        return recent_screenshots

    def _call_llm(self, prompt: str, frames=None) -> str:
        """
        Unified LLM call supporting OpenAI, Claude, and Gemini

        Works for both subtask and non-subtask modes.

        Args:
            prompt: Prompt text
            frames: List of (step, PIL.Image) tuples or single PIL Image (backward compatibility)

        Returns:
            LLM response text
        """
        # Normalize to list of tuples
        if frames is None:
            frames_with_steps = []
        elif not isinstance(frames, list):
            # Single frame (backward compatibility) - no step info
            frames_with_steps = [(None, frames)]
        else:
            # Check if it's already list of tuples
            if frames and isinstance(frames[0], tuple):
                frames_with_steps = frames  # Already (step, frame) format
            else:
                # Old format: list of frames without steps
                frames_with_steps = [(None, frame) for frame in frames]

        # Reverse order: newest (most important) first
        if frames_with_steps:
            frames_with_steps = frames_with_steps[::-1]

        if self.provider == "openai":
            # OpenAI format
            input_content = [{"type": "input_text", "text": prompt}]
            total = len(frames_with_steps)

            # Add multiple images with labels (reversed: newest first)
            for i, (step, frame) in enumerate(frames_with_steps, 1):
                # Add label before each image
                if step is not None:
                    if i == 1:
                        # First screenshot = current state
                        label = f"[CURRENT STATE ‚≠ê] Screenshot 1/{total} (Step {step}):"
                    elif i < total:
                        # Middle screenshots = recent history
                        steps_ago = i - 1
                        label = f"[History -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                    else:
                        # Last screenshot = oldest
                        steps_ago = i - 1
                        label = f"[OLDEST, -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                else:
                    label = f"Screenshot {i}:"

                input_content.append({"type": "input_text", "text": label})

                # Add image
                screenshot_b64 = self._get_screenshot_base64_from_frame(frame)
                if screenshot_b64:
                    input_content.append({
                        "type": "input_image",
                        "image_url": f"data:image/png;base64,{screenshot_b64}"
                    })

            response = self.client.responses.create(
                model=self.model,
                instructions="You are a Pokemon Emerald AI coding assistant. Generate clean, executable Python code based on visual and text information.",
                input=[{"role": "user", "content": input_content}],
                reasoning={"effort": "low"},
            )
            return response.output_text

        elif self.provider == "claude":
            # Claude format
            content = [{"type": "text", "text": prompt}]
            total = len(frames_with_steps)

            # Add multiple images with labels (reversed: newest first)
            for i, (step, frame) in enumerate(frames_with_steps, 1):
                # Add label before each image
                if step is not None:
                    if i == 1:
                        # First screenshot = current state
                        label = f"[CURRENT STATE ‚≠ê] Screenshot 1/{total} (Step {step}):"
                    elif i < total:
                        # Middle screenshots = recent history
                        steps_ago = i - 1
                        label = f"[History -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                    else:
                        # Last screenshot = oldest
                        steps_ago = i - 1
                        label = f"[OLDEST, -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                else:
                    label = f"Screenshot {i}:"

                content.append({"type": "text", "text": label})

                # Add image
                screenshot_b64 = self._get_screenshot_base64_from_frame(frame)
                if screenshot_b64:
                    content.append({
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": screenshot_b64
                        }
                    })

            response = self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                messages=[{"role": "user", "content": content}]
            )
            return response.content[0].text

        else:  # gemini
            # Gemini format - uses PIL Image directly
            content_parts = [prompt]
            total = len(frames_with_steps)

            # Add multiple images with labels (reversed: newest first)
            for i, (step, frame) in enumerate(frames_with_steps, 1):
                # Add label before each image
                if step is not None:
                    if i == 1:
                        # First screenshot = current state
                        label = f"[CURRENT STATE ‚≠ê] Screenshot 1/{total} (Step {step}):"
                    elif i < total:
                        # Middle screenshots = recent history
                        steps_ago = i - 1
                        label = f"[History -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                    else:
                        # Last screenshot = oldest
                        steps_ago = i - 1
                        label = f"[OLDEST, -{steps_ago} steps ago] Screenshot {i}/{total} (Step {step}):"
                else:
                    label = f"Screenshot {i}:"

                content_parts.append(label)
                content_parts.append(frame)

            response = self.client.generate_content(content_parts)

            # Check for safety filter
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason') and candidate.finish_reason == 12:
                    print("‚ö†Ô∏è Gemini safety filter triggered, trying text-only...")
                    # Retry with text only
                    response = self.client.generate_content([prompt])

            return response.text

    def _extract_code(self, text):
        """Extract code from structured LLM response"""
        # Try to find CODE: section first (for structured responses)
        # Important: Match standalone CODE: line to avoid matching "PREVIOUS CODE:" etc.
        lines = text.split('\n')
        code_section_start = -1

        for i, line in enumerate(lines):
            # Match CODE: as a standalone section header (exact match after strip)
            if line.strip() == 'CODE:':
                code_section_start = i
                break

        if code_section_start >= 0:
            # Get everything after the CODE: line
            code_section = '\n'.join(lines[code_section_start + 1:])

            # Extract from code block if present
            if "```python" in code_section:
                return code_section.split("```python")[1].split("```")[0].strip()
            elif "```" in code_section:
                return code_section.split("```")[1].split("```")[0].strip()

            # If no code block, take everything after CODE:
            # until we hit another section or end
            code_lines = []
            for line in code_section.split('\n'):
                # Stop at next section header (uppercase headers with colon)
                if any(line.strip().startswith(section) for section in ['ANALYSIS:', 'OBJECTIVES:', 'PLAN:', 'REASONING:', 'TASK_DECOMPOSITION:']):
                    break
                code_lines.append(line)

            extracted = '\n'.join(code_lines).strip()
            if extracted:
                return extracted

        # Fallback to old behavior (for non-structured responses)
        if "```python" in text:
            return text.split("```python")[1].split("```")[0].strip()
        elif "```" in text:
            return text.split("```")[1].split("```")[0].strip()

        return text.strip()

    def _execute_code(self, code, state):
        """
        Execute generated code with State object supporting VLM queries

        Args:
            code: Python code string with run(state) function
            state: Game state dict (raw format)

        Returns:
            action string (e.g., 'up', 'a')
        """
        try:
            # Clear schema registry before each execution
            schema_registry = get_global_schema_registry()
            schema_registry.clear()

            # Convert state to same format LLM saw in prompt
            formatted_state = convert_state_to_dict(state)

            # Log collection for this execution step
            step_logs = []

            def log(message: str):
                """
                Record a message during code execution
                Can be called from generated code for debugging

                Args:
                    message: Message to log
                """
                step_logs.append(str(message))

            # Create execution environment with add_to_state_schema and log
            exec_globals = {
                'add_to_state_schema': add_to_state_schema,
                'log': log
            }

            # Execute code with 15-second timeout
            def timeout_handler(signum, frame):
                raise TimeoutError("Code execution exceeded 15 seconds")

            old_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(15)  # 15Ï¥à timeout

            # Execute code (timeout will cover exec + State creation + run() call)
            exec(code, exec_globals)

            # Create State object with VLM support
            screenshot = state.get('frame')
            state_obj = State(
                base_data=formatted_state,
                schema_registry=schema_registry,
                vlm_caller=lambda screenshot, prompt, return_type: self.vlm_caller.call(
                    screenshot, prompt, return_type
                ),
                screenshot=screenshot
            )

            # Call run function with State object
            if 'run' in exec_globals:
                action = exec_globals['run'](state_obj)

                # Cancel alarm after run() completes successfully
                signal.alarm(0)
                signal.signal(signal.SIGALRM, old_handler)

                # Log VLM accesses for debugging
                vlm_log = state_obj.get_vlm_access_log()
                if vlm_log:
                    print(f"üîç VLM queries made: {len(vlm_log)}")
                    for entry in vlm_log:
                        print(f"   {entry['key']}: {entry['result']} ({entry['return_type']})")

                # Save execution logs
                if step_logs:
                    for msg in step_logs:
                        self.execution_logs.append((self.step_count, msg))
                        print(f"üìù [Step {self.step_count}] {msg}")

                    # Keep only the most recent max_logs entries
                    if len(self.execution_logs) > self.max_logs:
                        self.execution_logs = self.execution_logs[-self.max_logs:]

                # Validate action (support single action or list of actions)
                valid_actions = ['a', 'b', 'start', 'select', 'up', 'down', 'left', 'right', 'no_op']

                # Support single action (str)
                if isinstance(action, str):
                    if action.lower() in valid_actions:
                        return action.lower()
                    else:
                        # Alarm already cancelled above
                        error_msg = f"Invalid action returned: {action}"
                        print(f"‚ö†Ô∏è {error_msg}, using 'b'")
                        self.last_execution_error = {
                            'error': error_msg,
                            'code': code
                        }
                        return 'b'

                # Support multiple actions (list)
                elif isinstance(action, list):
                    if len(action) == 0:
                        # Alarm already cancelled above
                        error_msg = "Empty action list returned"
                        print(f"‚ö†Ô∏è {error_msg}, using 'b'")
                        self.last_execution_error = {
                            'error': error_msg,
                            'code': code
                        }
                        return 'b'

                    # Validate each action in the list
                    validated_actions = []
                    for act in action:
                        if isinstance(act, str) and act.lower() in valid_actions:
                            validated_actions.append(act.lower())
                        else:
                            # Alarm already cancelled above
                            error_msg = f"Invalid action in list: {act}"
                            print(f"‚ö†Ô∏è {error_msg}, using 'b'")
                            self.last_execution_error = {
                                'error': error_msg,
                                'code': code
                            }
                            return 'b'

                    return validated_actions  # Return list of validated actions

                # Invalid type
                else:
                    # Alarm already cancelled above
                    error_msg = f"Invalid action type returned: {type(action).__name__} (expected str or list)"
                    print(f"‚ö†Ô∏è {error_msg}, using 'b'")
                    self.last_execution_error = {
                        'error': error_msg,
                        'code': code
                    }
                    return 'b'
            else:
                # Cancel alarm if no run function found
                signal.alarm(0)
                signal.signal(signal.SIGALRM, old_handler)

                error_msg = "No 'run' function found in code"
                print(f"‚ö†Ô∏è {error_msg}, using 'b'")
                self.last_execution_error = {
                    'error': error_msg,
                    'code': code
                }
                return 'b'

        except TimeoutError as e:
            # Cancel alarm on timeout
            signal.alarm(0)
            signal.signal(signal.SIGALRM, old_handler)
            error_msg = f"Code execution timeout: {str(e)}"
            print(f"‚è∞ {error_msg}")
            print(f"Code:\n{code}")

            self.last_execution_error = {
                'error': error_msg,
                'code': code,
                'type': 'timeout'
            }

            return 'b'  # Default action on timeout

        except Exception as e:
            # Cancel alarm on any exception
            try:
                signal.alarm(0)
                signal.signal(signal.SIGALRM, old_handler)
            except:
                pass  # If signal cleanup fails, continue with error handling

            import traceback
            error_msg = f"Code execution error: {str(e)}"
            traceback_str = traceback.format_exc()

            print(f"‚ùå {error_msg}")
            print(f"Code:\n{code}")
            print(traceback_str)

            self.last_execution_error = {
                'error': error_msg,
                'code': code,
                'traceback': traceback_str
            }

            return 'no_op'  # No-op action on error (don't make things worse)

    def _parse_and_update_knowledge(self, llm_response: str, current_milestone: str):
        """
        Parse LLM response for ADD_KNOWLEDGE, UPDATE_KNOWLEDGE, DELETE_KNOWLEDGE commands

        Args:
            llm_response: Full LLM response text
            current_milestone: Current milestone ID for metadata
        """
        for line in llm_response.split('\n'):
            line = line.strip()

            # ADD_KNOWLEDGE: <content>
            if line.startswith("ADD_KNOWLEDGE:"):
                content = line.split("ADD_KNOWLEDGE:", 1)[1].strip()
                if content:
                    entry_id = self.knowledge_base.add(
                        content=content,
                        step=self.step_count,
                        milestone=current_milestone
                    )
                    print(f"üìù Knowledge added [{entry_id}]: {content}")

            # UPDATE_KNOWLEDGE: <ID> ‚Üí <new_content>
            elif line.startswith("UPDATE_KNOWLEDGE:"):
                rest = line.split("UPDATE_KNOWLEDGE:", 1)[1].strip()

                # Support both ‚Üí and ->
                if "‚Üí" in rest:
                    separator = "‚Üí"
                elif "->" in rest:
                    separator = "->"
                else:
                    print(f"‚ö†Ô∏è Invalid UPDATE_KNOWLEDGE format (missing ‚Üí or ->): {rest}")
                    continue

                parts = rest.split(separator, 1)
                if len(parts) == 2:
                    entry_id = parts[0].strip()
                    new_content = parts[1].strip()

                    if entry_id and new_content:
                        success = self.knowledge_base.update_by_id(
                            entry_id=entry_id,
                            new_content=new_content,
                            step=self.step_count,
                            milestone=current_milestone
                        )
                        if success:
                            print(f"üìù Knowledge updated [{entry_id}]: {new_content}")
                        else:
                            print(f"‚ö†Ô∏è Knowledge ID not found: {entry_id}")
                else:
                    print(f"‚ö†Ô∏è Invalid UPDATE_KNOWLEDGE format: {rest}")

            # DELETE_KNOWLEDGE: <ID>
            elif line.startswith("DELETE_KNOWLEDGE:"):
                entry_id = line.split("DELETE_KNOWLEDGE:", 1)[1].strip()
                if entry_id:
                    success = self.knowledge_base.delete_by_id(entry_id)
                    if success:
                        print(f"üóëÔ∏è Knowledge deleted [{entry_id}]")
                    else:
                        print(f"‚ö†Ô∏è Knowledge ID not found for deletion: {entry_id}")

    def _extract_analysis(self, response: str) -> str:
        """
        Extract ANALYSIS section from response (works for both subtask and non-subtask modes)

        Args:
            response: LLM response text

        Returns:
            Extracted ANALYSIS text
        """
        # Find ANALYSIS: marker
        start = response.find('ANALYSIS:')
        if start == -1:
            return ""

        # Extract content after ANALYSIS:
        content = response[start + len('ANALYSIS:'):]

        # Find the earliest occurrence of any known section header
        min_pos = len(content)
        for header in self.SECTION_HEADERS:
            pos = content.find(header)
            if pos != -1 and pos < min_pos:
                min_pos = pos

        # Extract content up to the next section (or end if no section found)
        return content[:min_pos].strip()

    def _register_custom_milestones(self):
        """Register custom milestones with completion conditions"""

        # Example: Clock interaction in bedroom
        def check_clock_interact(game_state, action):
            """
            Check if clock interaction happened:
            - Player at position (5, 2) - the tile BEFORE moving up to the clock
            - Action: exactly ['up', 'a'] sequence (move up to clock, then interact)

            Note: We check position BEFORE action execution, so we check (5,2) not (5,1).
            Action sequence must be exactly 2 actions in order.
            Single actions or sequences longer than 2 will not count.
            """
            player = game_state.get("player", {})
            pos = player.get("position", {})

            # Must be at position (5,2) - the tile before moving up to clock at (5,1)
            if not (pos.get("x") == 5 and pos.get("y") == 2):
                return False

            # Must be a list action with exactly ['up', 'a']
            if isinstance(action, list):
                return (len(action) == 2 and
                        action[0] == 'up' and
                        action[1] == 'a')

            # Single actions don't count
            return False

        # Add to milestone manager
        self.milestone_manager.add_custom_milestone(
            milestone_id="CLOCK_INTERACT",
            description="From position (5,2) in player bedroom, execute action sequence ['up', 'a'] to move up to the clock and interact with it",
            insert_after="PLAYER_BEDROOM",
            check_fn=check_clock_interact,
            category="custom"
        )

        # Example: Leave the house (same condition as CLOCK_SET)
        def check_leave_house(game_state, action):
            """
            Check if player left the house (same logic as CLOCK_SET):
            - Player location must be in Littleroot Town
            - NOT in any house or lab (outside)

            Note: This is a location-based check, action parameter is not used.
            Prerequisite check (CLOCK_INTERACT completed) is handled by _check_custom_milestones.
            """
            player = game_state.get("player", {})
            location = player.get("location", "")
            location_upper = str(location).upper()

            # In Littleroot but NOT in either house or lab
            return ("LITTLEROOT" in location_upper and
                    "HOUSE" not in location_upper and
                    "LAB" not in location_upper)

        # Add to milestone manager
        self.milestone_manager.add_custom_milestone(
            milestone_id="LEAVE_HOUSE",
            description="Leave the house and return to Littleroot Town (outside)",
            insert_after="CLOCK_INTERACT",
            check_fn=check_leave_house,
            category="custom"
        )

        # Pokedex dialog confirmation
        def check_pokedex_dialog(game_state, action):
            """
            Check if Pokedex dialog text appeared in Birch's lab:
            - Must be in Birch's lab location
            - Dialog text contains 'POK√©DEX', 'POKEDEX', or variants (√© is unicode U+00E9)

            Note: This is a dialog-based check, action parameter is not used.
            """
            # Check location first
            player = game_state.get("player", {})
            location = player.get("location", "")
            location_upper = str(location).upper()

            # Must be in Birch's lab
            if "LITTLEROOT TOWN PROFESSOR BIRCHS LAB" not in location_upper:
                return False

            # Check dialog text
            dialog_text = game_state.get("game", {}).get("dialog_text", "")
            dialog_upper = str(dialog_text).upper()

            # Check multiple variants (√© with acute accent, regular e, etc.)
            return ("POKEDEX" in dialog_upper or
                    "POK√âDEX" in dialog_upper or
                    "POK√©DEX" in dialog_upper or
                    "POKEDE'X" in dialog_upper or
                    # Fallback: contains both "POK" and "DEX"
                    ("POK" in dialog_upper and "DEX" in dialog_upper))

        # Add to milestone manager
        self.milestone_manager.add_custom_milestone(
            milestone_id="POKEDEX_DIALOG_CONFIRMED",
            description="Pokedex dialog text appeared in Birch's lab (POKEDEX or POKEDE'X in dialog at PROFESSOR BIRCHS LAB)",
            insert_after="ROUTE_103",
            check_fn=check_pokedex_dialog,
            category="dialog"
        )

        # May interaction on Route 103
        def check_may_interaction(game_state, action):
            """
            Check if May interaction/battle happened on Route 103:
            - Must be on Route 103
            - Dialog text contains 'MAY' or battle-related keywords

            Note: This is a dialog-based check, action parameter is not used.
            """
            # Check location first
            player = game_state.get("player", {})
            location = player.get("location", "")
            location_upper = str(location).upper()

            # Must be on Route 103
            if not ("ROUTE_103" in location_upper or "ROUTE 103" in location_upper):
                return False

            # Check dialog text for May or battle keywords
            dialog_text = game_state.get("game", {}).get("dialog_text", "")
            dialog_upper = str(dialog_text).upper()

            # Check for May's name or battle-related text
            return "MAY: I think I know why my dad" in dialog_upper

        # Add to milestone manager
        self.milestone_manager.add_custom_milestone(
            milestone_id="MAY_ROUTE103_INTERACTION",
            description="Interact with May on Route 103 (dialog contains MAY, BATTLE, or TRAINER keywords)",
            insert_after="ROUTE_103",
            check_fn=check_may_interaction,
            category="dialog"
        )

    def _check_custom_milestones(self, game_state, action):
        """
        Check and track custom milestone completions (client-side only)

        Args:
            game_state: Current game state from server
            action: Action that was just executed
        """
        # Get augmented milestones (server's + custom)
        milestones = self._get_augmented_milestones(game_state)

        for custom in self.milestone_manager.custom_milestones:
            milestone_id = custom["id"]

            # Skip if already completed
            if milestones.get(milestone_id, {}).get('completed', False):
                continue

            # Check if previous milestone is completed
            insert_after_id = custom["insert_after"]
            if not milestones.get(insert_after_id, {}).get('completed', False):
                continue

            # Check condition
            check_fn = custom["check_fn"]
            try:
                if check_fn(game_state, action):
                    print(f"üéØ Custom milestone completed: {milestone_id}")
                    self.custom_milestone_completions[milestone_id] = {
                        'completed': True,
                        'timestamp': time.time()
                    }
            except Exception as e:
                print(f"‚ö†Ô∏è Error checking custom milestone {milestone_id}: {e}")

    def _get_augmented_milestones(self, game_state):
        """
        Merge server's milestones with client's custom milestone completions

        Args:
            game_state: Game state from server

        Returns:
            Combined milestone dict (server + custom)
        """
        # Start with server's milestones
        milestones = game_state.get('milestones', {}).copy()

        # Add custom milestone completions
        milestones.update(self.custom_milestone_completions)

        return milestones

    def determine_situation(self, current_subtask, state):
        """
        Determine current situation for subtask-based processing

        Args:
            current_subtask: Current active subtask dict (or None)
            state: Current game state dict (raw format)

        Returns:
            str: One of "SUCCESS_ACHIEVED", "PRECONDITION_FAILED", "STUCK", "NORMAL"
        """
        # No subtask = NORMAL (initial state or progressing without subtasks)
        if not current_subtask:
            return "NORMAL"

        # Convert state to same format as policy code sees
        # This ensures conditions use the same structure shown in prompts
        from utils.state_formatter import convert_state_to_dict
        formatted_state = convert_state_to_dict(state)

        # Get last action for condition evaluation
        prev_action = self._last_action

        # Check SUCCESS condition first
        if current_subtask.get('success_condition'):
            success, result, error_msg = self.subtask_manager.evaluate_condition(
                current_subtask['success_condition'], formatted_state, prev_action
            )
            if not success:
                # Condition evaluation failed - set error and return STUCK
                print(f"‚ö†Ô∏è Success condition evaluation failed: {error_msg}")
                self.last_execution_error = {
                    'error': f"Success condition evaluation failed: {error_msg}",
                    'condition': current_subtask['success_condition'],
                    'type': 'condition_error'
                }
                return "STUCK"
            elif result:
                return "SUCCESS_ACHIEVED"

        # Check PRECONDITION
        if current_subtask.get('precondition'):
            success, result, error_msg = self.subtask_manager.evaluate_condition(
                current_subtask['precondition'], formatted_state, prev_action
            )
            if not success:
                # Precondition evaluation failed - set error and return STUCK
                print(f"‚ö†Ô∏è Precondition evaluation failed: {error_msg}")
                self.last_execution_error = {
                    'error': f"Precondition evaluation failed: {error_msg}",
                    'condition': current_subtask['precondition'],
                    'type': 'condition_error'
                }
                return "STUCK"
            elif not result:
                # Precondition explicitly not met
                return "PRECONDITION_FAILED"

        # Check STUCK (using existing stuck detector - use raw state for position check)
        if self.stuck_detector.check_stuck(state):
            self.stuck_detector.reset()
            return "STUCK"

        # Otherwise NORMAL (progressing normally)
        return "NORMAL"


    def parse_unified_response(self, response):
        """
        Parse VLM response for subtask-based code generation

        Extracts two main sections:
        - TASK_DECOMPOSITION: Decision on subtask management (includes condition modification)
        - CODE: Policy implementation

        Args:
            response: VLM response string

        Returns:
            dict with:
                - task_decision: 'KEEP_CURRENT' | 'CREATE_OR_MODIFY' | 'DECOMPOSE'
                - new_subtask: dict with description, precondition, success_condition (if CREATE_OR_MODIFY/DECOMPOSE)
                - code: str (policy code)
        """
        result = {}

        try:
            # Extract TASK_DECOMPOSITION section
            decomp_section = self._extract_section(response, 'TASK_DECOMPOSITION:', 'CODE:')

            # Parse decision
            decision_line = [line for line in decomp_section.split('\n') if 'Decision:' in line]
            if decision_line:
                decision_text = decision_line[0].split('Decision:')[-1].strip().upper()

                if 'KEEP_CURRENT' in decision_text:
                    result['task_decision'] = 'KEEP_CURRENT'
                elif 'CREATE_OR_MODIFY' in decision_text:
                    result['task_decision'] = 'CREATE_OR_MODIFY'
                elif 'DECOMPOSE' in decision_text:
                    result['task_decision'] = 'DECOMPOSE'
                else:
                    result['task_decision'] = 'KEEP_CURRENT'  # default
            else:
                result['task_decision'] = 'KEEP_CURRENT'  # default

            # If CREATE_OR_MODIFY or DECOMPOSE, extract subtask info
            if result['task_decision'] in ['CREATE_OR_MODIFY', 'DECOMPOSE']:
                desc = self._extract_after_marker(decomp_section, 'Description:')
                pre = self._extract_after_marker(decomp_section, 'Precondition:')
                succ = self._extract_after_marker(decomp_section, 'Success Condition:')

                if desc.strip():
                    result['new_subtask'] = {
                        'description': desc.strip(),
                        'precondition': pre.strip(),
                        'success_condition': succ.strip()
                    }
                else:
                    result['new_subtask'] = None
            else:
                result['new_subtask'] = None

            # Extract CODE section (reuse existing _extract_code method)
            result['code'] = self._extract_code(response)

        except Exception as e:
            print(f"‚ö†Ô∏è Error parsing unified response: {e}")
            # Return safe defaults
            result = {
                'task_decision': 'KEEP_CURRENT',
                'new_subtask': None,
                'code': 'return "no_op"  # Parse error - do nothing'
            }

        return result

    def _extract_section(self, text, start_marker, end_marker):
        """
        Extract text between two markers

        Args:
            text: Source text
            start_marker: Starting marker (e.g., 'TASK_DECOMPOSITION:')
            end_marker: Ending marker (e.g., 'CONDITION_REFINEMENT:')

        Returns:
            Extracted section text
        """
        try:
            start_idx = text.find(start_marker)
            if start_idx == -1:
                return ""

            # Start after the marker
            start_idx += len(start_marker)

            end_idx = text.find(end_marker, start_idx)
            if end_idx == -1:
                # If no end marker, take until end of text
                return text[start_idx:].strip()

            return text[start_idx:end_idx].strip()

        except Exception as e:
            print(f"‚ö†Ô∏è Error extracting section {start_marker} to {end_marker}: {e}")
            return ""

    def _extract_after_marker(self, text, marker):
        """
        Extract text after a marker until the next line that starts with a capital letter marker

        Args:
            text: Source text
            marker: Marker to find (e.g., 'Description:')

        Returns:
            Extracted text
        """
        try:
            idx = text.find(marker)
            if idx == -1:
                return ""

            # Start after marker
            start = idx + len(marker)

            # Find next line
            lines = text[start:].split('\n')
            if not lines:
                return ""

            # First line after marker
            first_line = lines[0].strip()

            # Check if we need to look at subsequent lines
            # Stop at next capitalized marker (e.g., "Description:", "Precondition:")
            result = [first_line]
            for line in lines[1:]:
                stripped = line.strip()
                # Stop if we hit another marker (starts with capital and has colon)
                if stripped and stripped[0].isupper() and ':' in stripped:
                    break
                if stripped:  # Non-empty line
                    result.append(stripped)

            return ' '.join(result).strip()

        except Exception as e:
            print(f"‚ö†Ô∏è Error extracting after marker {marker}: {e}")
            return ""

    def create_next_subtask(self, main_milestone, subtask_data, state):
        """
        Create next subtask (only one at a time)

        Args:
            main_milestone: Main milestone dict
            subtask_data: dict with description, precondition, success_condition
            state: Current game state

        Returns:
            Created subtask dict
        """
        from datetime import datetime

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        subtask_id = f"{main_milestone['id']}_subtask_{timestamp}"

        subtask = {
            'id': subtask_id,
            'parent_milestone_id': main_milestone['id'],
            'description': subtask_data['description'],
            'precondition': subtask_data.get('precondition', ''),
            'success_condition': subtask_data.get('success_condition', ''),
            'code': None,
            'created_at': timestamp
        }

        # Set in SubtaskManager (also registers as custom milestone)
        self.subtask_manager.set_current_subtask(subtask)

        print(f"üìç Created new subtask: {subtask['description']}")
        print(f"   Precondition: {subtask['precondition']}")
        print(f"   Success: {subtask['success_condition']}")

        return subtask

    def _should_summarize_analyses(self) -> bool:
        """
        Check if we should summarize analyses based on count

        Returns:
            True if analysis count reaches threshold (default: 20)
        """
        return len(self.previous_analyses) >= self.analysis_threshold

    def _summarize_and_reset_analyses(self):
        """
        Summarize all analyses and reset to single summary entry

        Process:
        1. Take all current previous_analyses (should be >= threshold)
        2. LLM summarize them into 1 entry
        3. Replace previous_analyses = [summary]

        Result: N entries ‚Üí 1 summary entry
        """
        current_count = len(self.previous_analyses)

        print(f"\n{'='*60}")
        print(f"üìù Analysis count reached {current_count} (threshold: {self.analysis_threshold})")
        print(f"   Creating summary to reduce context size...")
        print(f"{'='*60}")

        # Generate summary
        try:
            step_label, summary_text = self.summarizer.summarize_analyses(
                self.previous_analyses
            )

            # Reset to single summary entry
            self.previous_analyses = [(step_label, summary_text)]

            print(f"  ‚úÖ Summary created for steps {step_label}")
            print(f"  üìâ Context reduced: {current_count} ‚Üí 1 entry")
            print(f"  üíæ Total summaries created: {self.summarizer.total_summaries_created}")
            print(f"{'='*60}\n")

        except Exception as e:
            print(f"  ‚ùå Summarization failed: {e}")
            print(f"  ‚ö†Ô∏è Keeping original analyses")
            import traceback
            traceback.print_exc()

            # Fallback: truncate to prevent unbounded growth
            if len(self.previous_analyses) > 30:
                print(f"  ‚ö†Ô∏è Truncating to last 30 analyses as fallback")
                self.previous_analyses = self.previous_analyses[-30:]

